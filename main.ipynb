{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "rw2m974_g0T0",
        "w2WJ_lXXg0T8",
        "1NOvl-e_g0US",
        "BZtYjeWzg0Ud",
        "ATagsrMkg0Uh",
        "QEpzykNCg0U1",
        "XEelMprtg0VB",
        "iPpEL03Ag0VM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walexi/fellowshipai/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ6A0O0wg0Sp",
        "colab_type": "text"
      },
      "source": [
        "# Edge-labeling Graph Neural Network for one-shot learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEJgZXyyg0St",
        "colab_type": "text"
      },
      "source": [
        "## Notebook Layout <a id='top'></a>\n",
        "  * [Imports](#imports)\n",
        "  * [Data](#data)\n",
        "    * [Loading](#data-loading)\n",
        "    *[Exploration](#exploration)\n",
        "  * [Model](#model)\n",
        "    * [Architecture and Instantiation](#model-architecture-inst)\n",
        "  * [Training & Evaluation](#training)\n",
        "  \n",
        "Please note that this notebook is structured such that each cell is meant to be run in sequence from top to bottom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIiQz2Bqg0Sw",
        "colab_type": "text"
      },
      "source": [
        "# Imports <a id='imports'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tXvZa4Lyiom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP4oTkGzMnHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a3370e15-549b-460b-ba2c-938184e08d5e"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 81kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 153kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 163kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 174kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 184kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 194kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 204kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 215kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcmRPEEg0Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from src.model import EmbeddingImagenet, GraphNetwork, ConvNet\n",
        "from src.torchtools import *\n",
        "from src.dataloader import Loader\n",
        "from src.learner import Learner\n",
        "import shutil\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM1IHQSag0S4",
        "colab_type": "text"
      },
      "source": [
        "# Data <a id='data'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw2m974_g0T0",
        "colab_type": "text"
      },
      "source": [
        "## Loading <a id='data-loading'></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-1lAECJg0T1",
        "colab_type": "code",
        "outputId": "4f37fee4-3e99-4b79-804d-7e7a946eeac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train_data = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=None)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip to ./omniglot_data/omniglot-py/images_background.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9469952it [00:02, 4444880.60it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting downloaded file: ./omniglot_data/omniglot-py/images_background.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkQjItBw1DzJ",
        "colab_type": "code",
        "outputId": "239c8788-23d7-4575-c34d-63630c642daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "eval_data = datasets.Omniglot(root='./omniglot_data/', download=True, background=False, transform=None)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip to ./omniglot_data/omniglot-py/images_evaluation.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6463488it [00:01, 3773342.19it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting downloaded file: ./omniglot_data/omniglot-py/images_evaluation.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_CYS1EP0ZI2",
        "colab_type": "text"
      },
      "source": [
        "## Exploration <a id='exploration'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03DGC6wU0zCL",
        "colab_type": "text"
      },
      "source": [
        "### Explore the background set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvlxGFg_0sZT",
        "colab_type": "code",
        "outputId": "c4d3943f-f69e-417c-dc54-85f06196d272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(eval_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g92tvv_1WYN",
        "colab_type": "code",
        "outputId": "8b986e7e-1474-49b5-a32d-9db732edee4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data._alphabets), len(eval_data._characters)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 659)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZfba6V23ky-",
        "colab_type": "code",
        "outputId": "3cecf13e-b2cd-42e7-ec1b-32ed3232fa8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "train_data._alphabets"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tifinagh',\n",
              " 'Japanese_(hiragana)',\n",
              " 'Inuktitut_(Canadian_Aboriginal_Syllabics)',\n",
              " 'Mkhedruli_(Georgian)',\n",
              " 'Syriac_(Estrangelo)',\n",
              " 'Korean',\n",
              " 'Sanskrit',\n",
              " 'Grantha',\n",
              " 'Balinese',\n",
              " 'Japanese_(katakana)',\n",
              " 'Tagalog',\n",
              " 'Hebrew',\n",
              " 'Cyrillic',\n",
              " 'Greek',\n",
              " 'Bengali',\n",
              " 'Arcadian',\n",
              " 'Burmese_(Myanmar)',\n",
              " 'Malay_(Jawi_-_Arabic)',\n",
              " 'Blackfoot_(Canadian_Aboriginal_Syllabics)',\n",
              " 'Braille',\n",
              " 'Armenian',\n",
              " 'Asomtavruli_(Georgian)',\n",
              " 'N_Ko',\n",
              " 'Gujarati',\n",
              " 'Anglo-Saxon_Futhorc',\n",
              " 'Futurama',\n",
              " 'Latin',\n",
              " 'Early_Aramaic',\n",
              " 'Ojibwe_(Canadian_Aboriginal_Syllabics)',\n",
              " 'Alphabet_of_the_Magi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK94m2gu3rov",
        "colab_type": "code",
        "outputId": "4ac55093-4fe8-4f37-ed23-db80a0c1783a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "# background set\n",
        "per_lang_count = dict()\n",
        "for a in train_data._alphabets:\n",
        "    per_lang_count['{}'.format(a)] = len(os.listdir(os.path.join(train_data.target_folder, a)))\n",
        "plt.bar(range(len(per_lang_count)), list(per_lang_count.values()))\n",
        "plt.title('Num of characters per language in Background Set')\n",
        "plt.show()\n",
        "print('maximum num of characters {}'.format(max(list(per_lang_count.values()))))\n",
        "print('mean num of characters {:.2f}'.format(np.mean(list(per_lang_count.values()))))\n",
        "print('median num of characters {}'.format(np.median(list(per_lang_count.values()))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuplZIRzoZmaF+H80Yoxufq2lZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "maximum num of characters 55\n",
            "mean num of characters 32.13\n",
            "median num of characters 31.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UbcQ-A3zUY",
        "colab_type": "code",
        "outputId": "290e8a9e-1000-409a-a5da-f257890486a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "ind = np.random.randint(len(train_data))\n",
        "img, target = train_data[ind]\n",
        "class_name = train_data._characters[target]\n",
        "plt.imshow(np.asarray(img), cmap='gray')\n",
        "print('class: {}, img shape: {}'.format(class_name, img.size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class: Greek/character08, img shape: (105, 105)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYVXX9dN4Az-",
        "colab_type": "text"
      },
      "source": [
        "### Explore the evaluation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ZneqIHDuGW",
        "colab_type": "code",
        "outputId": "590c15b5-353a-4fc0-9012-73dc460417e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(eval_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UU4vIDADziO",
        "colab_type": "code",
        "outputId": "43e4be90-081c-44c7-e7ed-ac6de0f5e6f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(eval_data._alphabets), len(eval_data._characters)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 659)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwn_LkBDD8uW",
        "colab_type": "code",
        "outputId": "8a959ee4-c18f-42f6-bedd-a1a63985b313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "eval_data._alphabets"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sylheti',\n",
              " 'Glagolitic',\n",
              " 'Oriya',\n",
              " 'Keble',\n",
              " 'Atemayar_Qelisayer',\n",
              " 'Tibetan',\n",
              " 'Kannada',\n",
              " 'Manipuri',\n",
              " 'Ge_ez',\n",
              " 'Tengwar',\n",
              " 'Atlantean',\n",
              " 'Syriac_(Serto)',\n",
              " 'Mongolian',\n",
              " 'Malayalam',\n",
              " 'Gurmukhi',\n",
              " 'Aurek-Besh',\n",
              " 'Angelic',\n",
              " 'ULOG',\n",
              " 'Avesta',\n",
              " 'Old_Church_Slavonic_(Cyrillic)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i43Y6B2HEC7V",
        "colab_type": "code",
        "outputId": "05424a46-6d3c-406f-cf8a-31ffdfa69b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "# evaluation set\n",
        "eval_per_lang_count = dict()\n",
        "for a in eval_data._alphabets:\n",
        "    eval_per_lang_count['{}'.format(a)] = len(os.listdir(os.path.join(eval_data.target_folder, a)))\n",
        "# num_eval_chars = list(eval_per_lang_count.values())\n",
        "plt.bar(range(len(eval_per_lang_count)), list(eval_per_lang_count.values()))\n",
        "plt.title('Num of characters per language in Evaluation Set')\n",
        "plt.show()\n",
        "print('maximum num of characters {}'.format(max(list(eval_per_lang_count.values()))))\n",
        "print('mean num of characters {:.2f}'.format(np.mean(list(eval_per_lang_count.values()))))\n",
        "print('median num of characters {}'.format(np.median(list(eval_per_lang_count.values()))))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEICAYAAACgQWTXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf4fc3sbYsON3/kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "maximum num of characters 47\n",
            "mean num of characters 32.95\n",
            "median num of characters 27.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBpyR87WEUGr",
        "colab_type": "code",
        "outputId": "eca76681-1338-4fe1-c93e-fe965d59d998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "ind = np.random.randint(len(eval_data))\n",
        "img, target = eval_data[ind]\n",
        "class_name = eval_data._characters[target]\n",
        "plt.imshow(np.asarray(img), cmap='gray')\n",
        "print('class: {}, img shape: {}'.format(class_name, img.size))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class: Old_Church_Slavonic_(Cyrillic)/character23, img shape: (105, 105)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "55CUenr80UTl"
      },
      "source": [
        "# Model <a id='model'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nd0lVzTvDkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_exp_name():\n",
        "    exp_name = 'D-{}'.format(tt.arg.dataset)\n",
        "    exp_name += '_N-{}_K-{}_U-{}'.format(tt.arg.num_ways, tt.arg.num_shots, tt.arg.num_unlabeled)\n",
        "    exp_name += '_L-{}_B-{}'.format(tt.arg.num_layers, tt.arg.meta_batch_size)\n",
        "    exp_name += '_T-{}'.format(tt.arg.transductive)\n",
        "    exp_name += '_SEED-{}'.format(tt.arg.seed)\n",
        "\n",
        "    return exp_name\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeSbc7DFf-F",
        "colab_type": "text"
      },
      "source": [
        "## Parameters <a id=\"parameter\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kBhx_l8Fal5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt.arg.device = 'cuda:0' if tt.arg.device is None else tt.arg.device\n",
        "tt.arg.dataset_root = 'omniglot_data/omniglot-py'\n",
        "tt.arg.num_ways = 20 if tt.arg.num_ways is None else tt.arg.num_ways\n",
        "tt.arg.num_shots = 1 if tt.arg.num_shots is None else tt.arg.num_shots\n",
        "tt.arg.num_unlabeled = 0 if tt.arg.num_unlabeled is None else tt.arg.num_unlabeled\n",
        "tt.arg.num_layers = 3 if tt.arg.num_layers is None else tt.arg.num_layers\n",
        "tt.arg.meta_batch_size = 10 if tt.arg.meta_batch_size is None else tt.arg.meta_batch_size\n",
        "tt.arg.transductive = False if tt.arg.transductive is None else tt.arg.transductive\n",
        "tt.arg.seed = 222 if tt.arg.seed is None else tt.arg.seed\n",
        "tt.arg.num_gpus = 1 if tt.arg.num_gpus is None else tt.arg.num_gpus\n",
        "\n",
        "tt.arg.num_ways_train = tt.arg.num_ways\n",
        "tt.arg.num_ways_test = tt.arg.num_ways\n",
        "\n",
        "tt.arg.num_shots_train = tt.arg.num_shots\n",
        "tt.arg.num_shots_test = tt.arg.num_shots\n",
        "\n",
        "tt.arg.train_transductive = tt.arg.transductive\n",
        "tt.arg.test_transductive = tt.arg.transductive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWaUrXMhGHBW",
        "colab_type": "text"
      },
      "source": [
        "### Model Parameters <a id=\"model_parameter\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBiNJ-NVCPr9",
        "colab_type": "text"
      },
      "source": [
        "Here we set the model parameters such as the number of edge features, node featrues and the size of embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjdF-DQCGJk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tt.arg.num_edge_features = 96\n",
        "tt.arg.num_node_features = 96\n",
        "tt.arg.emb_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbx3dbo3Gln2",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Parameters <a id=\"train_test_parameters\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwDVRuDJB79w",
        "colab_type": "text"
      },
      "source": [
        "Here, we set the parameters for training and testing, just enough to test and see that the modified model from the paper works with our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGVR6Rc2GZzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt.arg.train_iteration = 100\n",
        "tt.arg.test_iteration = 10\n",
        "tt.arg.test_interval = 5\n",
        "tt.arg.test_batch_size = 10\n",
        "tt.arg.log_step = 1\n",
        "\n",
        "tt.arg.lr = 1e-3\n",
        "tt.arg.grad_clip = 5\n",
        "tt.arg.weight_decay = 1e-6\n",
        "tt.arg.dec_lr = 15000\n",
        "tt.arg.dropout = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcwSk8ZZvA0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dd4a7cc-d81b-4850-a3e4-cc596403f860"
      },
      "source": [
        "tt.arg.experiment = set_exp_name() if tt.arg.experiment is None else tt.arg.experiment\n",
        "print(set_exp_name())\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D-None_N-20_K-1_U-0_L-3_B-10_T-False_SEED-222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DAaVuTSI31b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(tt.arg.seed)\n",
        "torch.manual_seed(tt.arg.seed)\n",
        "torch.cuda.manual_seed_all(tt.arg.seed)\n",
        "random.seed(tt.arg.seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "tt.arg.log_dir_user = tt.arg.log_dir if tt.arg.log_dir_user is None else tt.arg.log_dir_user\n",
        "tt.arg.log_dir = tt.arg.log_dir_user\n",
        "\n",
        "if not os.path.exists('asset/checkpoints'):\n",
        "    os.makedirs('asset/checkpoints')\n",
        "if not os.path.exists('asset/checkpoints/' + tt.arg.experiment):\n",
        "    os.makedirs('asset/checkpoints/' + tt.arg.experiment)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB8HF7a0BvdP",
        "colab_type": "text"
      },
      "source": [
        "Here, we load the training and validation dataset and put them in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dczcjOP003ZN",
        "colab_type": "code",
        "outputId": "f0412675-73a8-4a82-c406-a88db7a7e865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loader = Loader(root=tt.arg.dataset_root, partition='train')\n",
        "valid_loader = Loader(root=tt.arg.dataset_root, partition='val')\n",
        "\n",
        "data_loader = {'train': train_loader, 'val': valid_loader}\n",
        "\n",
        "    \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Burmese_(Myanmar)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Burmese_(Myanmar) is 34\n",
            "Total number of images in Burmese_(Myanmar) is: 680\n",
            "loading alphabet: Korean\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Korean is 40\n",
            "Total number of images in Korean is: 800\n",
            "loading alphabet: Japanese_(hiragana)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Japanese_(hiragana) is 52\n",
            "Total number of images in Japanese_(hiragana) is: 1040\n",
            "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Blackfoot_(Canadian_Aboriginal_Syllabics) is 14\n",
            "Total number of images in Blackfoot_(Canadian_Aboriginal_Syllabics) is: 280\n",
            "loading alphabet: Malay_(Jawi_-_Arabic)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Malay_(Jawi_-_Arabic) is 40\n",
            "Total number of images in Malay_(Jawi_-_Arabic) is: 800\n",
            "loading alphabet: Balinese\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Balinese is 24\n",
            "Total number of images in Balinese is: 480\n",
            "loading alphabet: N_Ko\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in N_Ko is 33\n",
            "Total number of images in N_Ko is: 660\n",
            "loading alphabet: Bengali\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Bengali is 46\n",
            "Total number of images in Bengali is: 920\n",
            "loading alphabet: Grantha\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Grantha is 43\n",
            "Total number of images in Grantha is: 860\n",
            "loading alphabet: Futurama\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Futurama is 26\n",
            "Total number of images in Futurama is: 520\n",
            "loading alphabet: Greek\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Greek is 24\n",
            "Total number of images in Greek is: 480\n",
            "loading alphabet: Alphabet_of_the_Magi\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Alphabet_of_the_Magi is 20\n",
            "Total number of images in Alphabet_of_the_Magi is: 400\n",
            "loading alphabet: Cyrillic\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Cyrillic is 33\n",
            "Total number of images in Cyrillic is: 660\n",
            "loading alphabet: Braille\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Braille is 26\n",
            "Total number of images in Braille is: 520\n",
            "loading alphabet: Arcadian\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Arcadian is 26\n",
            "Total number of images in Arcadian is: 520\n",
            "loading alphabet: Syriac_(Estrangelo)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Syriac_(Estrangelo) is 23\n",
            "Total number of images in Syriac_(Estrangelo) is: 460\n",
            "loading alphabet: Tagalog\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Tagalog is 17\n",
            "Total number of images in Tagalog is: 340\n",
            "loading alphabet: Armenian\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Armenian is 41\n",
            "Total number of images in Armenian is: 820\n",
            "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Inuktitut_(Canadian_Aboriginal_Syllabics) is 16\n",
            "Total number of images in Inuktitut_(Canadian_Aboriginal_Syllabics) is: 320\n",
            "loading alphabet: Asomtavruli_(Georgian)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Asomtavruli_(Georgian) is 40\n",
            "Total number of images in Asomtavruli_(Georgian) is: 800\n",
            "loading alphabet: Gujarati\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Gujarati is 48\n",
            "Total number of images in Gujarati is: 960\n",
            "loading alphabet: Japanese_(katakana)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Japanese_(katakana) is 47\n",
            "Total number of images in Japanese_(katakana) is: 940\n",
            "loading alphabet: Latin\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Latin is 26\n",
            "Total number of images in Latin is: 520\n",
            "loading alphabet: Mkhedruli_(Georgian)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Mkhedruli_(Georgian) is 41\n",
            "Total number of images in Mkhedruli_(Georgian) is: 820\n",
            "loading alphabet: Hebrew\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Hebrew is 22\n",
            "Total number of images in Hebrew is: 440\n",
            "loading alphabet: Early_Aramaic\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Early_Aramaic is 22\n",
            "Total number of images in Early_Aramaic is: 440\n",
            "loading alphabet: Tifinagh\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Tifinagh is 55\n",
            "Total number of images in Tifinagh is: 1100\n",
            "loading alphabet: Anglo-Saxon_Futhorc\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Anglo-Saxon_Futhorc is 29\n",
            "Total number of images in Anglo-Saxon_Futhorc is: 580\n",
            "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Ojibwe_(Canadian_Aboriginal_Syllabics) is 14\n",
            "Total number of images in Ojibwe_(Canadian_Aboriginal_Syllabics) is: 280\n",
            "loading alphabet: Sanskrit\n",
            "Total number of alphabet: 30\n",
            "Total number of character sets in Sanskrit is 42\n",
            "Total number of images in Sanskrit is: 840\n",
            "loading alphabet: Glagolitic\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Glagolitic is 45\n",
            "Total number of images in Glagolitic is: 900\n",
            "loading alphabet: Tibetan\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Tibetan is 42\n",
            "Total number of images in Tibetan is: 840\n",
            "loading alphabet: Angelic\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Angelic is 20\n",
            "Total number of images in Angelic is: 400\n",
            "loading alphabet: Malayalam\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Malayalam is 47\n",
            "Total number of images in Malayalam is: 940\n",
            "loading alphabet: Kannada\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Kannada is 41\n",
            "Total number of images in Kannada is: 820\n",
            "loading alphabet: Mongolian\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Mongolian is 30\n",
            "Total number of images in Mongolian is: 600\n",
            "loading alphabet: Atlantean\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Atlantean is 26\n",
            "Total number of images in Atlantean is: 520\n",
            "loading alphabet: Old_Church_Slavonic_(Cyrillic)\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Old_Church_Slavonic_(Cyrillic) is 45\n",
            "Total number of images in Old_Church_Slavonic_(Cyrillic) is: 900\n",
            "loading alphabet: Tengwar\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Tengwar is 25\n",
            "Total number of images in Tengwar is: 500\n",
            "loading alphabet: Atemayar_Qelisayer\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Atemayar_Qelisayer is 26\n",
            "Total number of images in Atemayar_Qelisayer is: 520\n",
            "loading alphabet: Sylheti\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Sylheti is 28\n",
            "Total number of images in Sylheti is: 560\n",
            "loading alphabet: Aurek-Besh\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Aurek-Besh is 26\n",
            "Total number of images in Aurek-Besh is: 520\n",
            "loading alphabet: Syriac_(Serto)\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Syriac_(Serto) is 23\n",
            "Total number of images in Syriac_(Serto) is: 460\n",
            "loading alphabet: Manipuri\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Manipuri is 40\n",
            "Total number of images in Manipuri is: 800\n",
            "loading alphabet: Gurmukhi\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Gurmukhi is 45\n",
            "Total number of images in Gurmukhi is: 900\n",
            "loading alphabet: Oriya\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Oriya is 46\n",
            "Total number of images in Oriya is: 920\n",
            "loading alphabet: ULOG\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in ULOG is 26\n",
            "Total number of images in ULOG is: 520\n",
            "loading alphabet: Ge_ez\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Ge_ez is 26\n",
            "Total number of images in Ge_ez is: 520\n",
            "loading alphabet: Avesta\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Avesta is 26\n",
            "Total number of images in Avesta is: 520\n",
            "loading alphabet: Keble\n",
            "Total number of alphabet: 20\n",
            "Total number of character sets in Keble is 26\n",
            "Total number of images in Keble is: 520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7nSRoDSHGAK",
        "colab_type": "text"
      },
      "source": [
        "## Architecture & Initialization <a id=\"initialization\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxBJT_BGBDfa",
        "colab_type": "text"
      },
      "source": [
        "Here, we define the encoder network and the graph network.\n",
        "\n",
        "The encoder network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m2tmpGIH6DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_module = EmbeddingNetwork(emb_size=tt.arg.emb_size)\n",
        "\n",
        "gnn_module = GraphNetwork(in_features=tt.arg.emb_size,\n",
        "                            node_features=tt.arg.num_edge_features,\n",
        "                            edge_features=tt.arg.num_node_features,\n",
        "                            num_layers=tt.arg.num_layers,\n",
        "                            dropout=tt.arg.dropout)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yEx_zT0g0Uc",
        "colab_type": "text"
      },
      "source": [
        "# Training & Evaluation <a id='training'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1pHOVEzBjfI",
        "colab_type": "text"
      },
      "source": [
        "Let's create a Learner and train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4aY5Z7x07tU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cca67093-9d72-4d44-850f-09a00e82e979"
      },
      "source": [
        "# create trainer\n",
        "trainer = Learner(enc_module=enc_module,\n",
        "                         gnn_module=gnn_module,\n",
        "                         data_loader=data_loader)\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " step: 1 train/edge_loss: 1.405455 train/edge_accr: 0.550125 train/node_accr: 0.050000 val/edge_loss: 1.386292 val/edge_accr: 0.509500 val/node_accr: 0.060000 val/best_accr: 0.060000\n",
            " step: 2 train/edge_loss: 1.365561 train/edge_accr: 0.552125 train/node_accr: 0.075000\n",
            " step: 3 train/edge_loss: 1.373965 train/edge_accr: 0.530250 train/node_accr: 0.090000\n",
            " step: 4 train/edge_loss: 1.377232 train/edge_accr: 0.524000 train/node_accr: 0.065000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=6.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 5 train/edge_loss: 1.390710 train/edge_accr: 0.504375 train/node_accr: 0.070000 val/edge_loss: 1.386286 val/edge_accr: 0.524000 val/node_accr: 0.065000 val/best_accr: 0.065000\n",
            " step: 6 train/edge_loss: 1.378315 train/edge_accr: 0.534125 train/node_accr: 0.095000\n",
            " step: 7 train/edge_loss: 1.380848 train/edge_accr: 0.536750 train/node_accr: 0.045000\n",
            " step: 8 train/edge_loss: 1.365948 train/edge_accr: 0.552250 train/node_accr: 0.075000\n",
            " step: 9 train/edge_loss: 1.364539 train/edge_accr: 0.552875 train/node_accr: 0.090000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=9.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 10 train/edge_loss: 1.356074 train/edge_accr: 0.560250 train/node_accr: 0.090000 val/edge_loss: 1.386144 val/edge_accr: 0.487875 val/node_accr: 0.095000 val/best_accr: 0.095000\n",
            " step: 11 train/edge_loss: 1.350878 train/edge_accr: 0.547500 train/node_accr: 0.100000\n",
            " step: 12 train/edge_loss: 1.345620 train/edge_accr: 0.548750 train/node_accr: 0.090000\n",
            " step: 13 train/edge_loss: 1.352592 train/edge_accr: 0.543375 train/node_accr: 0.085000\n",
            " step: 14 train/edge_loss: 1.325297 train/edge_accr: 0.547375 train/node_accr: 0.110000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=15.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 15 train/edge_loss: 1.326913 train/edge_accr: 0.538750 train/node_accr: 0.100000 val/edge_loss: 1.382097 val/edge_accr: 0.494000 val/node_accr: 0.150000 val/best_accr: 0.150000\n",
            " step: 16 train/edge_loss: 1.303867 train/edge_accr: 0.551875 train/node_accr: 0.090000\n",
            " step: 17 train/edge_loss: 1.302204 train/edge_accr: 0.531125 train/node_accr: 0.110000\n",
            " step: 18 train/edge_loss: 1.281803 train/edge_accr: 0.545250 train/node_accr: 0.095000\n",
            " step: 19 train/edge_loss: 1.268724 train/edge_accr: 0.531500 train/node_accr: 0.105000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=18.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 20 train/edge_loss: 1.281530 train/edge_accr: 0.548000 train/node_accr: 0.115000 val/edge_loss: 1.362674 val/edge_accr: 0.488625 val/node_accr: 0.185000 val/best_accr: 0.185000\n",
            " step: 21 train/edge_loss: 1.253758 train/edge_accr: 0.537125 train/node_accr: 0.135000\n",
            " step: 22 train/edge_loss: 1.244127 train/edge_accr: 0.543000 train/node_accr: 0.130000\n",
            " step: 23 train/edge_loss: 1.233914 train/edge_accr: 0.556750 train/node_accr: 0.150000\n",
            " step: 24 train/edge_loss: 1.262582 train/edge_accr: 0.536500 train/node_accr: 0.105000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=19.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 25 train/edge_loss: 1.219598 train/edge_accr: 0.544625 train/node_accr: 0.145000 val/edge_loss: 1.317747 val/edge_accr: 0.505375 val/node_accr: 0.190000 val/best_accr: 0.190000\n",
            " step: 26 train/edge_loss: 1.224562 train/edge_accr: 0.545250 train/node_accr: 0.145000\n",
            " step: 27 train/edge_loss: 1.208436 train/edge_accr: 0.562000 train/node_accr: 0.195000\n",
            " step: 28 train/edge_loss: 1.208030 train/edge_accr: 0.581875 train/node_accr: 0.175000\n",
            " step: 29 train/edge_loss: 1.193557 train/edge_accr: 0.575875 train/node_accr: 0.145000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=20.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 30 train/edge_loss: 1.184348 train/edge_accr: 0.591125 train/node_accr: 0.155000 val/edge_loss: 1.263218 val/edge_accr: 0.521875 val/node_accr: 0.200000 val/best_accr: 0.200000\n",
            " step: 31 train/edge_loss: 1.174149 train/edge_accr: 0.573625 train/node_accr: 0.205000\n",
            " step: 32 train/edge_loss: 1.162796 train/edge_accr: 0.578375 train/node_accr: 0.165000\n",
            " step: 33 train/edge_loss: 1.176807 train/edge_accr: 0.580375 train/node_accr: 0.190000\n",
            " step: 34 train/edge_loss: 1.146201 train/edge_accr: 0.594500 train/node_accr: 0.215000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=22.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 35 train/edge_loss: 1.157608 train/edge_accr: 0.590500 train/node_accr: 0.195000 val/edge_loss: 1.212574 val/edge_accr: 0.560125 val/node_accr: 0.220000 val/best_accr: 0.220000\n",
            " step: 36 train/edge_loss: 1.128558 train/edge_accr: 0.600750 train/node_accr: 0.210000\n",
            " step: 37 train/edge_loss: 1.131302 train/edge_accr: 0.605375 train/node_accr: 0.250000\n",
            " step: 38 train/edge_loss: 1.182999 train/edge_accr: 0.616625 train/node_accr: 0.215000\n",
            " step: 39 train/edge_loss: 1.073618 train/edge_accr: 0.625000 train/node_accr: 0.285000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=26.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 40 train/edge_loss: 1.096735 train/edge_accr: 0.615125 train/node_accr: 0.295000 val/edge_loss: 1.159010 val/edge_accr: 0.603750 val/node_accr: 0.260000 val/best_accr: 0.260000\n",
            " step: 41 train/edge_loss: 1.094075 train/edge_accr: 0.652500 train/node_accr: 0.340000\n",
            " step: 42 train/edge_loss: 1.081059 train/edge_accr: 0.643750 train/node_accr: 0.335000\n",
            " step: 43 train/edge_loss: 1.058415 train/edge_accr: 0.642125 train/node_accr: 0.320000\n",
            " step: 44 train/edge_loss: 1.055186 train/edge_accr: 0.666125 train/node_accr: 0.295000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=26.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 45 train/edge_loss: 1.061254 train/edge_accr: 0.670250 train/node_accr: 0.290000 val/edge_loss: 1.152469 val/edge_accr: 0.637500 val/node_accr: 0.260000 val/best_accr: 0.260000\n",
            " step: 46 train/edge_loss: 1.041567 train/edge_accr: 0.675375 train/node_accr: 0.355000\n",
            " step: 47 train/edge_loss: 1.010841 train/edge_accr: 0.681000 train/node_accr: 0.395000\n",
            " step: 48 train/edge_loss: 1.031819 train/edge_accr: 0.689875 train/node_accr: 0.385000\n",
            " step: 49 train/edge_loss: 1.046287 train/edge_accr: 0.696125 train/node_accr: 0.310000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=26.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 50 train/edge_loss: 1.064617 train/edge_accr: 0.699750 train/node_accr: 0.320000 val/edge_loss: 1.143961 val/edge_accr: 0.667250 val/node_accr: 0.265000 val/best_accr: 0.265000\n",
            " step: 51 train/edge_loss: 1.013776 train/edge_accr: 0.680000 train/node_accr: 0.365000\n",
            " step: 52 train/edge_loss: 1.025977 train/edge_accr: 0.697875 train/node_accr: 0.265000\n",
            " step: 53 train/edge_loss: 1.011932 train/edge_accr: 0.704375 train/node_accr: 0.385000\n",
            " step: 54 train/edge_loss: 1.039364 train/edge_accr: 0.695875 train/node_accr: 0.340000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=27.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 55 train/edge_loss: 0.965298 train/edge_accr: 0.712250 train/node_accr: 0.400000 val/edge_loss: 1.136655 val/edge_accr: 0.682500 val/node_accr: 0.275000 val/best_accr: 0.275000\n",
            " step: 56 train/edge_loss: 1.004540 train/edge_accr: 0.716625 train/node_accr: 0.330000\n",
            " step: 57 train/edge_loss: 0.945424 train/edge_accr: 0.716500 train/node_accr: 0.450000\n",
            " step: 58 train/edge_loss: 0.963668 train/edge_accr: 0.717500 train/node_accr: 0.425000\n",
            " step: 59 train/edge_loss: 0.967278 train/edge_accr: 0.734250 train/node_accr: 0.390000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=27.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 60 train/edge_loss: 0.984253 train/edge_accr: 0.728625 train/node_accr: 0.335000 val/edge_loss: 1.109928 val/edge_accr: 0.699875 val/node_accr: 0.270000 val/best_accr: 0.275000\n",
            " step: 61 train/edge_loss: 0.935235 train/edge_accr: 0.743625 train/node_accr: 0.435000\n",
            " step: 62 train/edge_loss: 0.938875 train/edge_accr: 0.737875 train/node_accr: 0.385000\n",
            " step: 63 train/edge_loss: 0.923919 train/edge_accr: 0.753250 train/node_accr: 0.400000\n",
            " step: 64 train/edge_loss: 0.989076 train/edge_accr: 0.742500 train/node_accr: 0.420000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=32.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 65 train/edge_loss: 0.940251 train/edge_accr: 0.759250 train/node_accr: 0.365000 val/edge_loss: 1.083322 val/edge_accr: 0.723375 val/node_accr: 0.325000 val/best_accr: 0.325000\n",
            " step: 66 train/edge_loss: 0.914282 train/edge_accr: 0.767125 train/node_accr: 0.425000\n",
            " step: 67 train/edge_loss: 0.957889 train/edge_accr: 0.757250 train/node_accr: 0.380000\n",
            " step: 68 train/edge_loss: 0.928032 train/edge_accr: 0.768500 train/node_accr: 0.395000\n",
            " step: 69 train/edge_loss: 0.913764 train/edge_accr: 0.771250 train/node_accr: 0.425000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=34.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 70 train/edge_loss: 0.900181 train/edge_accr: 0.768250 train/node_accr: 0.435000 val/edge_loss: 1.058671 val/edge_accr: 0.727750 val/node_accr: 0.340000 val/best_accr: 0.340000\n",
            " step: 71 train/edge_loss: 0.883220 train/edge_accr: 0.772000 train/node_accr: 0.425000\n",
            " step: 72 train/edge_loss: 0.880140 train/edge_accr: 0.763125 train/node_accr: 0.465000\n",
            " step: 73 train/edge_loss: 0.924730 train/edge_accr: 0.764125 train/node_accr: 0.425000\n",
            " step: 74 train/edge_loss: 0.867583 train/edge_accr: 0.774750 train/node_accr: 0.450000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=33.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 75 train/edge_loss: 0.860457 train/edge_accr: 0.778000 train/node_accr: 0.475000 val/edge_loss: 1.086395 val/edge_accr: 0.733000 val/node_accr: 0.335000 val/best_accr: 0.340000\n",
            " step: 76 train/edge_loss: 0.895875 train/edge_accr: 0.770875 train/node_accr: 0.420000\n",
            " step: 77 train/edge_loss: 0.892804 train/edge_accr: 0.788125 train/node_accr: 0.445000\n",
            " step: 78 train/edge_loss: 0.825411 train/edge_accr: 0.797375 train/node_accr: 0.465000\n",
            " step: 79 train/edge_loss: 0.876207 train/edge_accr: 0.805250 train/node_accr: 0.415000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=34.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 80 train/edge_loss: 0.853059 train/edge_accr: 0.796750 train/node_accr: 0.435000 val/edge_loss: 1.144605 val/edge_accr: 0.730875 val/node_accr: 0.345000 val/best_accr: 0.345000\n",
            " step: 81 train/edge_loss: 0.824769 train/edge_accr: 0.805500 train/node_accr: 0.445000\n",
            " step: 82 train/edge_loss: 0.915901 train/edge_accr: 0.801250 train/node_accr: 0.440000\n",
            " step: 83 train/edge_loss: 0.846291 train/edge_accr: 0.800125 train/node_accr: 0.415000\n",
            " step: 84 train/edge_loss: 0.829978 train/edge_accr: 0.794375 train/node_accr: 0.485000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=35.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 85 train/edge_loss: 0.837862 train/edge_accr: 0.803500 train/node_accr: 0.485000 val/edge_loss: 1.087497 val/edge_accr: 0.733375 val/node_accr: 0.355000 val/best_accr: 0.355000\n",
            " step: 86 train/edge_loss: 0.876538 train/edge_accr: 0.802250 train/node_accr: 0.425000\n",
            " step: 87 train/edge_loss: 0.867960 train/edge_accr: 0.801000 train/node_accr: 0.450000\n",
            " step: 88 train/edge_loss: 0.829387 train/edge_accr: 0.814500 train/node_accr: 0.490000\n",
            " step: 89 train/edge_loss: 0.868780 train/edge_accr: 0.805125 train/node_accr: 0.445000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=37.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 90 train/edge_loss: 0.813724 train/edge_accr: 0.809500 train/node_accr: 0.510000 val/edge_loss: 1.073241 val/edge_accr: 0.734000 val/node_accr: 0.375000 val/best_accr: 0.375000\n",
            " step: 91 train/edge_loss: 0.880119 train/edge_accr: 0.798875 train/node_accr: 0.420000\n",
            " step: 92 train/edge_loss: 0.819919 train/edge_accr: 0.805000 train/node_accr: 0.475000\n",
            " step: 93 train/edge_loss: 0.845875 train/edge_accr: 0.807500 train/node_accr: 0.440000\n",
            " step: 94 train/edge_loss: 0.822400 train/edge_accr: 0.801625 train/node_accr: 0.485000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=37.50%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 95 train/edge_loss: 0.803784 train/edge_accr: 0.811625 train/node_accr: 0.485000 val/edge_loss: 1.026034 val/edge_accr: 0.745000 val/node_accr: 0.375000 val/best_accr: 0.375000\n",
            " step: 96 train/edge_loss: 0.831457 train/edge_accr: 0.803875 train/node_accr: 0.490000\n",
            " step: 97 train/edge_loss: 0.862380 train/edge_accr: 0.802500 train/node_accr: 0.470000\n",
            " step: 98 train/edge_loss: 0.807632 train/edge_accr: 0.811125 train/node_accr: 0.455000\n",
            " step: 99 train/edge_loss: 0.774137 train/edge_accr: 0.805125 train/node_accr: 0.510000\n",
            "---------------------------\n",
            "evaluation: total_count=0, accuracy: mean=36.00%, std=0.00%, ci95=0.00%\n",
            "---------------------------\n",
            " step: 100 train/edge_loss: 0.795253 train/edge_accr: 0.816125 train/node_accr: 0.470000 val/edge_loss: 1.008059 val/edge_accr: 0.755125 val/node_accr: 0.360000 val/best_accr: 0.375000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3emz45PXArD2",
        "colab_type": "text"
      },
      "source": [
        "Training for a longer period seems to improve the model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1H5obfEw8MT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt.arg.train_iteration = 100000 if tt.arg.dataset == 'mini' else 200000\n",
        "tt.arg.test_iteration = 10000\n",
        "tt.arg.test_interval = 5000 if tt.arg.test_interval is None else tt.arg.test_interval\n",
        "tt.arg.test_batch_size = 10\n",
        "tt.arg.log_step = 1000 if tt.arg.log_step is None else tt.arg.log_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-mDj-PZxE5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_module = EmbeddingImagenet(emb_size=tt.arg.emb_size)\n",
        "\n",
        "gnn_module = GraphNetwork(in_features=tt.arg.emb_size,\n",
        "                            node_features=tt.arg.num_edge_features,\n",
        "                            edge_features=tt.arg.num_node_features,\n",
        "                            num_layers=tt.arg.num_layers,\n",
        "                            dropout=tt.arg.dropout)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud4LyQ9AxIZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7516f8b1-2a9c-44ad-a40a-5aa5ee1e66ec"
      },
      "source": [
        "# create trainer\n",
        "trainer = Learner(enc_module=enc_module,\n",
        "                         gnn_module=gnn_module,\n",
        "                         data_loader=data_loader)\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " step: 1 train/edge_loss: 1.407240 train/edge_accr: 0.552375 train/node_accr: 0.035000\n",
            " step: 2 train/edge_loss: 1.396267 train/edge_accr: 0.571000 train/node_accr: 0.035000\n",
            " step: 3 train/edge_loss: 1.403775 train/edge_accr: 0.550875 train/node_accr: 0.055000\n",
            " step: 4 train/edge_loss: 1.416085 train/edge_accr: 0.541500 train/node_accr: 0.020000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=10.45%, std=2.05%, ci95=0.13%\n",
            "---------------------------\n",
            " step: 5 train/edge_loss: 1.401651 train/edge_accr: 0.536750 train/node_accr: 0.035000 val/edge_loss: 1.386284 val/edge_accr: 0.573699 val/node_accr: 0.104520 val/best_accr: 0.104520\n",
            " step: 6 train/edge_loss: 1.388816 train/edge_accr: 0.508125 train/node_accr: 0.080000\n",
            " step: 7 train/edge_loss: 1.394475 train/edge_accr: 0.492375 train/node_accr: 0.060000\n",
            " step: 8 train/edge_loss: 1.389594 train/edge_accr: 0.497375 train/node_accr: 0.035000\n",
            " step: 9 train/edge_loss: 1.383609 train/edge_accr: 0.527500 train/node_accr: 0.075000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=12.19%, std=2.24%, ci95=0.14%\n",
            "---------------------------\n",
            " step: 10 train/edge_loss: 1.368407 train/edge_accr: 0.524875 train/node_accr: 0.065000 val/edge_loss: 1.386225 val/edge_accr: 0.551057 val/node_accr: 0.121855 val/best_accr: 0.121855\n",
            " step: 11 train/edge_loss: 1.392377 train/edge_accr: 0.538000 train/node_accr: 0.070000\n",
            " step: 12 train/edge_loss: 1.374443 train/edge_accr: 0.539000 train/node_accr: 0.075000\n",
            " step: 13 train/edge_loss: 1.368268 train/edge_accr: 0.550125 train/node_accr: 0.080000\n",
            " step: 14 train/edge_loss: 1.338076 train/edge_accr: 0.566000 train/node_accr: 0.115000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=17.07%, std=2.44%, ci95=0.15%\n",
            "---------------------------\n",
            " step: 15 train/edge_loss: 1.348611 train/edge_accr: 0.553375 train/node_accr: 0.130000 val/edge_loss: 1.385592 val/edge_accr: 0.574597 val/node_accr: 0.170740 val/best_accr: 0.170740\n",
            " step: 16 train/edge_loss: 1.334388 train/edge_accr: 0.538500 train/node_accr: 0.110000\n",
            " step: 17 train/edge_loss: 1.331037 train/edge_accr: 0.553750 train/node_accr: 0.110000\n",
            " step: 18 train/edge_loss: 1.324987 train/edge_accr: 0.568125 train/node_accr: 0.095000\n",
            " step: 19 train/edge_loss: 1.308619 train/edge_accr: 0.551250 train/node_accr: 0.135000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=18.11%, std=2.57%, ci95=0.16%\n",
            "---------------------------\n",
            " step: 20 train/edge_loss: 1.308080 train/edge_accr: 0.547750 train/node_accr: 0.125000 val/edge_loss: 1.382085 val/edge_accr: 0.552611 val/node_accr: 0.181110 val/best_accr: 0.181110\n",
            " step: 21 train/edge_loss: 1.273654 train/edge_accr: 0.553500 train/node_accr: 0.140000\n",
            " step: 22 train/edge_loss: 1.288538 train/edge_accr: 0.551750 train/node_accr: 0.110000\n",
            " step: 23 train/edge_loss: 1.240734 train/edge_accr: 0.561250 train/node_accr: 0.155000\n",
            " step: 24 train/edge_loss: 1.261244 train/edge_accr: 0.556500 train/node_accr: 0.145000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=17.70%, std=2.44%, ci95=0.15%\n",
            "---------------------------\n",
            " step: 25 train/edge_loss: 1.253665 train/edge_accr: 0.553375 train/node_accr: 0.150000 val/edge_loss: 1.368906 val/edge_accr: 0.511728 val/node_accr: 0.177020 val/best_accr: 0.181110\n",
            " step: 26 train/edge_loss: 1.243155 train/edge_accr: 0.561375 train/node_accr: 0.130000\n",
            " step: 27 train/edge_loss: 1.210495 train/edge_accr: 0.565125 train/node_accr: 0.230000\n",
            " step: 28 train/edge_loss: 1.259655 train/edge_accr: 0.557875 train/node_accr: 0.155000\n",
            " step: 29 train/edge_loss: 1.200067 train/edge_accr: 0.582125 train/node_accr: 0.150000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=20.10%, std=2.52%, ci95=0.16%\n",
            "---------------------------\n",
            " step: 30 train/edge_loss: 1.216702 train/edge_accr: 0.576125 train/node_accr: 0.185000 val/edge_loss: 1.323730 val/edge_accr: 0.484456 val/node_accr: 0.201005 val/best_accr: 0.201005\n",
            " step: 31 train/edge_loss: 1.215270 train/edge_accr: 0.573375 train/node_accr: 0.225000\n",
            " step: 32 train/edge_loss: 1.179599 train/edge_accr: 0.571000 train/node_accr: 0.200000\n",
            " step: 33 train/edge_loss: 1.167424 train/edge_accr: 0.580125 train/node_accr: 0.165000\n",
            " step: 34 train/edge_loss: 1.150094 train/edge_accr: 0.587750 train/node_accr: 0.250000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=23.18%, std=2.51%, ci95=0.16%\n",
            "---------------------------\n",
            " step: 35 train/edge_loss: 1.173290 train/edge_accr: 0.600375 train/node_accr: 0.205000 val/edge_loss: 1.256970 val/edge_accr: 0.511738 val/node_accr: 0.231800 val/best_accr: 0.231800\n",
            " step: 36 train/edge_loss: 1.122241 train/edge_accr: 0.611625 train/node_accr: 0.260000\n",
            " step: 37 train/edge_loss: 1.120403 train/edge_accr: 0.632000 train/node_accr: 0.300000\n",
            " step: 38 train/edge_loss: 1.137823 train/edge_accr: 0.621250 train/node_accr: 0.245000\n",
            " step: 39 train/edge_loss: 1.074532 train/edge_accr: 0.628625 train/node_accr: 0.290000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=24.54%, std=2.51%, ci95=0.16%\n",
            "---------------------------\n",
            " step: 40 train/edge_loss: 1.117411 train/edge_accr: 0.631875 train/node_accr: 0.250000 val/edge_loss: 1.196161 val/edge_accr: 0.548677 val/node_accr: 0.245435 val/best_accr: 0.245435\n",
            " step: 41 train/edge_loss: 1.137653 train/edge_accr: 0.642500 train/node_accr: 0.270000\n",
            " step: 42 train/edge_loss: 1.110471 train/edge_accr: 0.653125 train/node_accr: 0.270000\n",
            " step: 43 train/edge_loss: 1.083156 train/edge_accr: 0.657000 train/node_accr: 0.310000\n",
            " step: 44 train/edge_loss: 1.062548 train/edge_accr: 0.678375 train/node_accr: 0.300000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=25.71%, std=2.60%, ci95=0.16%\n",
            "---------------------------\n",
            " step: 45 train/edge_loss: 1.096161 train/edge_accr: 0.684125 train/node_accr: 0.290000 val/edge_loss: 1.166190 val/edge_accr: 0.567403 val/node_accr: 0.257060 val/best_accr: 0.257060\n",
            " step: 46 train/edge_loss: 1.058856 train/edge_accr: 0.682875 train/node_accr: 0.335000\n",
            " step: 47 train/edge_loss: 1.012450 train/edge_accr: 0.687500 train/node_accr: 0.350000\n",
            " step: 48 train/edge_loss: 1.019298 train/edge_accr: 0.685375 train/node_accr: 0.300000\n",
            " step: 49 train/edge_loss: 1.042561 train/edge_accr: 0.697125 train/node_accr: 0.325000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=27.50%, std=2.67%, ci95=0.17%\n",
            "---------------------------\n",
            " step: 50 train/edge_loss: 1.022575 train/edge_accr: 0.697000 train/node_accr: 0.325000 val/edge_loss: 1.146927 val/edge_accr: 0.594882 val/node_accr: 0.275040 val/best_accr: 0.275040\n",
            " step: 51 train/edge_loss: 1.000386 train/edge_accr: 0.692375 train/node_accr: 0.390000\n",
            " step: 52 train/edge_loss: 1.024714 train/edge_accr: 0.697250 train/node_accr: 0.340000\n",
            " step: 53 train/edge_loss: 1.020838 train/edge_accr: 0.701125 train/node_accr: 0.360000\n",
            " step: 54 train/edge_loss: 1.037869 train/edge_accr: 0.697250 train/node_accr: 0.355000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=28.26%, std=2.81%, ci95=0.17%\n",
            "---------------------------\n",
            " step: 55 train/edge_loss: 0.992394 train/edge_accr: 0.705875 train/node_accr: 0.335000 val/edge_loss: 1.146871 val/edge_accr: 0.609435 val/node_accr: 0.282645 val/best_accr: 0.282645\n",
            " step: 56 train/edge_loss: 1.028452 train/edge_accr: 0.696125 train/node_accr: 0.270000\n",
            " step: 57 train/edge_loss: 0.970417 train/edge_accr: 0.712125 train/node_accr: 0.375000\n",
            " step: 58 train/edge_loss: 0.966538 train/edge_accr: 0.708750 train/node_accr: 0.340000\n",
            " step: 59 train/edge_loss: 0.932445 train/edge_accr: 0.713250 train/node_accr: 0.410000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=29.57%, std=2.93%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 60 train/edge_loss: 1.027819 train/edge_accr: 0.710125 train/node_accr: 0.310000 val/edge_loss: 1.138159 val/edge_accr: 0.624308 val/node_accr: 0.295710 val/best_accr: 0.295710\n",
            " step: 61 train/edge_loss: 0.956958 train/edge_accr: 0.730000 train/node_accr: 0.355000\n",
            " step: 62 train/edge_loss: 0.936295 train/edge_accr: 0.733000 train/node_accr: 0.380000\n",
            " step: 63 train/edge_loss: 0.924728 train/edge_accr: 0.748250 train/node_accr: 0.385000\n",
            " step: 64 train/edge_loss: 0.926606 train/edge_accr: 0.743125 train/node_accr: 0.410000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=31.21%, std=3.06%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 65 train/edge_loss: 0.914282 train/edge_accr: 0.749500 train/node_accr: 0.365000 val/edge_loss: 1.129038 val/edge_accr: 0.632860 val/node_accr: 0.312095 val/best_accr: 0.312095\n",
            " step: 66 train/edge_loss: 0.887769 train/edge_accr: 0.760750 train/node_accr: 0.430000\n",
            " step: 67 train/edge_loss: 0.935253 train/edge_accr: 0.751625 train/node_accr: 0.330000\n",
            " step: 68 train/edge_loss: 0.875300 train/edge_accr: 0.762500 train/node_accr: 0.470000\n",
            " step: 69 train/edge_loss: 0.881857 train/edge_accr: 0.770750 train/node_accr: 0.435000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=32.35%, std=3.03%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 70 train/edge_loss: 0.884249 train/edge_accr: 0.764250 train/node_accr: 0.435000 val/edge_loss: 1.114559 val/edge_accr: 0.629463 val/node_accr: 0.323545 val/best_accr: 0.323545\n",
            " step: 71 train/edge_loss: 0.864660 train/edge_accr: 0.777000 train/node_accr: 0.510000\n",
            " step: 72 train/edge_loss: 0.877342 train/edge_accr: 0.787250 train/node_accr: 0.420000\n",
            " step: 73 train/edge_loss: 0.913623 train/edge_accr: 0.785625 train/node_accr: 0.390000\n",
            " step: 74 train/edge_loss: 0.880897 train/edge_accr: 0.792000 train/node_accr: 0.445000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=33.34%, std=2.96%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 75 train/edge_loss: 0.846161 train/edge_accr: 0.792250 train/node_accr: 0.485000 val/edge_loss: 1.094691 val/edge_accr: 0.661269 val/node_accr: 0.333365 val/best_accr: 0.333365\n",
            " step: 76 train/edge_loss: 0.819123 train/edge_accr: 0.782125 train/node_accr: 0.510000\n",
            " step: 77 train/edge_loss: 0.877365 train/edge_accr: 0.787125 train/node_accr: 0.425000\n",
            " step: 78 train/edge_loss: 0.846423 train/edge_accr: 0.783750 train/node_accr: 0.480000\n",
            " step: 79 train/edge_loss: 0.842911 train/edge_accr: 0.791500 train/node_accr: 0.460000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=32.89%, std=2.93%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 80 train/edge_loss: 0.822927 train/edge_accr: 0.795375 train/node_accr: 0.420000 val/edge_loss: 1.081341 val/edge_accr: 0.667136 val/node_accr: 0.328870 val/best_accr: 0.333365\n",
            " step: 81 train/edge_loss: 0.847063 train/edge_accr: 0.802750 train/node_accr: 0.425000\n",
            " step: 82 train/edge_loss: 0.867617 train/edge_accr: 0.792000 train/node_accr: 0.455000\n",
            " step: 83 train/edge_loss: 0.777981 train/edge_accr: 0.796625 train/node_accr: 0.450000\n",
            " step: 84 train/edge_loss: 0.806676 train/edge_accr: 0.809125 train/node_accr: 0.510000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=35.28%, std=3.05%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 85 train/edge_loss: 0.798696 train/edge_accr: 0.813875 train/node_accr: 0.485000 val/edge_loss: 1.064426 val/edge_accr: 0.678703 val/node_accr: 0.352830 val/best_accr: 0.352830\n",
            " step: 86 train/edge_loss: 0.849679 train/edge_accr: 0.816250 train/node_accr: 0.420000\n",
            " step: 87 train/edge_loss: 0.798607 train/edge_accr: 0.827625 train/node_accr: 0.450000\n",
            " step: 88 train/edge_loss: 0.828615 train/edge_accr: 0.805000 train/node_accr: 0.495000\n",
            " step: 89 train/edge_loss: 0.824484 train/edge_accr: 0.805875 train/node_accr: 0.450000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=35.79%, std=3.03%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 90 train/edge_loss: 0.783753 train/edge_accr: 0.806875 train/node_accr: 0.525000 val/edge_loss: 1.059073 val/edge_accr: 0.689949 val/node_accr: 0.357865 val/best_accr: 0.357865\n",
            " step: 91 train/edge_loss: 0.794740 train/edge_accr: 0.798375 train/node_accr: 0.520000\n",
            " step: 92 train/edge_loss: 0.792868 train/edge_accr: 0.806375 train/node_accr: 0.460000\n",
            " step: 93 train/edge_loss: 0.767258 train/edge_accr: 0.811500 train/node_accr: 0.535000\n",
            " step: 94 train/edge_loss: 0.735972 train/edge_accr: 0.818000 train/node_accr: 0.555000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=36.28%, std=2.90%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 95 train/edge_loss: 0.747825 train/edge_accr: 0.824125 train/node_accr: 0.580000 val/edge_loss: 1.031087 val/edge_accr: 0.699915 val/node_accr: 0.362820 val/best_accr: 0.362820\n",
            " step: 96 train/edge_loss: 0.765585 train/edge_accr: 0.826875 train/node_accr: 0.500000\n",
            " step: 97 train/edge_loss: 0.734430 train/edge_accr: 0.831750 train/node_accr: 0.510000\n",
            " step: 98 train/edge_loss: 0.712144 train/edge_accr: 0.840625 train/node_accr: 0.585000\n",
            " step: 99 train/edge_loss: 0.736553 train/edge_accr: 0.838250 train/node_accr: 0.515000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=36.95%, std=2.98%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 100 train/edge_loss: 0.733055 train/edge_accr: 0.843875 train/node_accr: 0.490000 val/edge_loss: 1.033664 val/edge_accr: 0.693873 val/node_accr: 0.369505 val/best_accr: 0.369505\n",
            " step: 101 train/edge_loss: 0.689573 train/edge_accr: 0.849000 train/node_accr: 0.545000\n",
            " step: 102 train/edge_loss: 0.696446 train/edge_accr: 0.848625 train/node_accr: 0.575000\n",
            " step: 103 train/edge_loss: 0.707513 train/edge_accr: 0.852125 train/node_accr: 0.550000\n",
            " step: 104 train/edge_loss: 0.740752 train/edge_accr: 0.850500 train/node_accr: 0.530000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=38.74%, std=3.03%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 105 train/edge_loss: 0.696321 train/edge_accr: 0.855500 train/node_accr: 0.520000 val/edge_loss: 1.015891 val/edge_accr: 0.714520 val/node_accr: 0.387355 val/best_accr: 0.387355\n",
            " step: 106 train/edge_loss: 0.710947 train/edge_accr: 0.857500 train/node_accr: 0.500000\n",
            " step: 107 train/edge_loss: 0.722329 train/edge_accr: 0.862000 train/node_accr: 0.545000\n",
            " step: 108 train/edge_loss: 0.655766 train/edge_accr: 0.861375 train/node_accr: 0.540000\n",
            " step: 109 train/edge_loss: 0.698949 train/edge_accr: 0.865750 train/node_accr: 0.520000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=38.73%, std=3.01%, ci95=0.19%\n",
            "---------------------------\n",
            " step: 110 train/edge_loss: 0.643326 train/edge_accr: 0.865125 train/node_accr: 0.590000 val/edge_loss: 1.010623 val/edge_accr: 0.729855 val/node_accr: 0.387320 val/best_accr: 0.387355\n",
            " step: 111 train/edge_loss: 0.653504 train/edge_accr: 0.854625 train/node_accr: 0.580000\n",
            " step: 112 train/edge_loss: 0.660171 train/edge_accr: 0.848250 train/node_accr: 0.635000\n",
            " step: 113 train/edge_loss: 0.609234 train/edge_accr: 0.863375 train/node_accr: 0.585000\n",
            " step: 114 train/edge_loss: 0.677054 train/edge_accr: 0.863750 train/node_accr: 0.560000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=38.48%, std=2.93%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 115 train/edge_loss: 0.622099 train/edge_accr: 0.863125 train/node_accr: 0.605000 val/edge_loss: 1.020170 val/edge_accr: 0.736369 val/node_accr: 0.384850 val/best_accr: 0.387355\n",
            " step: 116 train/edge_loss: 0.730157 train/edge_accr: 0.863125 train/node_accr: 0.565000\n",
            " step: 117 train/edge_loss: 0.651600 train/edge_accr: 0.863375 train/node_accr: 0.565000\n",
            " step: 118 train/edge_loss: 0.609479 train/edge_accr: 0.871750 train/node_accr: 0.605000\n",
            " step: 119 train/edge_loss: 0.641599 train/edge_accr: 0.872875 train/node_accr: 0.570000\n",
            "---------------------------\n",
            "evaluation: total_count=999, accuracy: mean=39.28%, std=2.87%, ci95=0.18%\n",
            "---------------------------\n",
            " step: 120 train/edge_loss: 0.573587 train/edge_accr: 0.869000 train/node_accr: 0.645000 val/edge_loss: 1.012156 val/edge_accr: 0.712288 val/node_accr: 0.392785 val/best_accr: 0.392785\n",
            " step: 121 train/edge_loss: 0.604629 train/edge_accr: 0.871500 train/node_accr: 0.620000\n",
            " step: 122 train/edge_loss: 0.634000 train/edge_accr: 0.884250 train/node_accr: 0.610000\n",
            " step: 123 train/edge_loss: 0.589289 train/edge_accr: 0.879750 train/node_accr: 0.605000\n",
            " step: 124 train/edge_loss: 0.653607 train/edge_accr: 0.872375 train/node_accr: 0.545000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}